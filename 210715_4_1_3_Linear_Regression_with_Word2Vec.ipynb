{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "4.1.3 Linear Regression with Word2Vec.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minalang/study/blob/main/210715_4_1_3_Linear_Regression_with_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv6zBB2DSwUf"
      },
      "source": [
        "## 4.1.3 Linear Regression Example with Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgrJwE4KSwUl"
      },
      "source": [
        "### Word2Vec Feature Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOrCoItlSwUm"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFX4_jAaSwUn"
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SPLIT = 0.2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xHLdjrvSwUn"
      },
      "source": [
        "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGhuNf_JSwUo"
      },
      "source": [
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drNs-DQlSwUo"
      },
      "source": [
        "sentences = []\n",
        "for review in reviews:\n",
        "    sentences.append(review.split())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYE7WxlZSwUp"
      },
      "source": [
        "num_features = 300    \n",
        "min_word_count = 40   \n",
        "num_workers = 4       \n",
        "context = 10          \n",
        "downsampling = 1e-3 "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE0qCwzsSwUq"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
        "   level=logging.INFO)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMfFVCyJSwUr",
        "outputId": "c92ead65-fc03-46eb-f233-79cf24ab1e2f"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
        "           size=num_features, min_count = min_word_count, \\\n",
        "            window = context, sample = downsampling)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-15 03:57:29,036 : INFO : 'pattern' package not found; tag filters are not available for English\n",
            "2021-07-15 03:57:29,054 : INFO : collecting all words and their counts\n",
            "2021-07-15 03:57:29,056 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-07-15 03:57:29,376 : INFO : PROGRESS: at sentence #10000, processed 1205223 words, keeping 51374 word types\n",
            "2021-07-15 03:57:29,684 : INFO : PROGRESS: at sentence #20000, processed 2396605 words, keeping 67660 word types\n",
            "2021-07-15 03:57:29,845 : INFO : collected 74065 word types from a corpus of 2988089 raw words and 25000 sentences\n",
            "2021-07-15 03:57:29,846 : INFO : Loading a fresh vocabulary\n",
            "2021-07-15 03:57:29,900 : INFO : effective_min_count=40 retains 8160 unique words (11% of original 74065, drops 65905)\n",
            "2021-07-15 03:57:29,901 : INFO : effective_min_count=40 leaves 2627273 word corpus (87% of original 2988089, drops 360816)\n",
            "2021-07-15 03:57:29,930 : INFO : deleting the raw counts dictionary of 74065 items\n",
            "2021-07-15 03:57:29,936 : INFO : sample=0.001 downsamples 30 most-common words\n",
            "2021-07-15 03:57:29,938 : INFO : downsampling leaves estimated 2494384 word corpus (94.9% of prior 2627273)\n",
            "2021-07-15 03:57:29,978 : INFO : estimated required memory for 8160 words and 300 dimensions: 23664000 bytes\n",
            "2021-07-15 03:57:29,980 : INFO : resetting layer weights\n",
            "2021-07-15 03:57:31,755 : INFO : training model with 4 workers on 8160 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
            "2021-07-15 03:57:32,772 : INFO : EPOCH 1 - PROGRESS: at 11.58% examples, 286537 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:33,777 : INFO : EPOCH 1 - PROGRESS: at 23.57% examples, 295364 words/s, in_qsize 6, out_qsize 1\n",
            "2021-07-15 03:57:34,802 : INFO : EPOCH 1 - PROGRESS: at 36.07% examples, 299258 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:35,807 : INFO : EPOCH 1 - PROGRESS: at 49.06% examples, 304869 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:36,825 : INFO : EPOCH 1 - PROGRESS: at 62.00% examples, 307427 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:37,856 : INFO : EPOCH 1 - PROGRESS: at 74.61% examples, 307125 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:38,899 : INFO : EPOCH 1 - PROGRESS: at 87.86% examples, 308702 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:39,736 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-07-15 03:57:39,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-07-15 03:57:39,769 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-07-15 03:57:39,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-07-15 03:57:39,782 : INFO : EPOCH - 1 : training on 2988089 raw words (2494537 effective words) took 8.0s, 311047 effective words/s\n",
            "2021-07-15 03:57:40,794 : INFO : EPOCH 2 - PROGRESS: at 12.22% examples, 304159 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:41,805 : INFO : EPOCH 2 - PROGRESS: at 24.28% examples, 303182 words/s, in_qsize 6, out_qsize 1\n",
            "2021-07-15 03:57:42,825 : INFO : EPOCH 2 - PROGRESS: at 37.39% examples, 310416 words/s, in_qsize 8, out_qsize 0\n",
            "2021-07-15 03:57:43,855 : INFO : EPOCH 2 - PROGRESS: at 50.35% examples, 311269 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:44,887 : INFO : EPOCH 2 - PROGRESS: at 63.33% examples, 312227 words/s, in_qsize 7, out_qsize 1\n",
            "2021-07-15 03:57:45,903 : INFO : EPOCH 2 - PROGRESS: at 76.68% examples, 314198 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:46,926 : INFO : EPOCH 2 - PROGRESS: at 89.23% examples, 313242 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:47,668 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-07-15 03:57:47,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-07-15 03:57:47,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-07-15 03:57:47,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-07-15 03:57:47,701 : INFO : EPOCH - 2 : training on 2988089 raw words (2494079 effective words) took 7.9s, 315213 effective words/s\n",
            "2021-07-15 03:57:48,749 : INFO : EPOCH 3 - PROGRESS: at 11.93% examples, 285731 words/s, in_qsize 5, out_qsize 2\n",
            "2021-07-15 03:57:49,821 : INFO : EPOCH 3 - PROGRESS: at 25.60% examples, 305042 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:50,877 : INFO : EPOCH 3 - PROGRESS: at 38.77% examples, 307973 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:51,878 : INFO : EPOCH 3 - PROGRESS: at 51.68% examples, 311527 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:52,938 : INFO : EPOCH 3 - PROGRESS: at 64.76% examples, 310284 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:53,959 : INFO : EPOCH 3 - PROGRESS: at 77.67% examples, 311340 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:54,975 : INFO : EPOCH 3 - PROGRESS: at 90.68% examples, 312216 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:55,606 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-07-15 03:57:55,613 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-07-15 03:57:55,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-07-15 03:57:55,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-07-15 03:57:55,640 : INFO : EPOCH - 3 : training on 2988089 raw words (2494616 effective words) took 7.9s, 314465 effective words/s\n",
            "2021-07-15 03:57:56,662 : INFO : EPOCH 4 - PROGRESS: at 12.52% examples, 309621 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:57,698 : INFO : EPOCH 4 - PROGRESS: at 25.65% examples, 314303 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:57:58,722 : INFO : EPOCH 4 - PROGRESS: at 38.46% examples, 314784 words/s, in_qsize 6, out_qsize 1\n",
            "2021-07-15 03:57:59,778 : INFO : EPOCH 4 - PROGRESS: at 51.72% examples, 314559 words/s, in_qsize 5, out_qsize 2\n",
            "2021-07-15 03:58:00,816 : INFO : EPOCH 4 - PROGRESS: at 65.10% examples, 315606 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:01,897 : INFO : EPOCH 4 - PROGRESS: at 78.71% examples, 315339 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:02,908 : INFO : EPOCH 4 - PROGRESS: at 91.70% examples, 315903 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:03,451 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-07-15 03:58:03,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-07-15 03:58:03,478 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-07-15 03:58:03,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-07-15 03:58:03,495 : INFO : EPOCH - 4 : training on 2988089 raw words (2494563 effective words) took 7.8s, 317868 effective words/s\n",
            "2021-07-15 03:58:04,517 : INFO : EPOCH 5 - PROGRESS: at 11.87% examples, 293700 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:05,526 : INFO : EPOCH 5 - PROGRESS: at 24.98% examples, 310494 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:06,529 : INFO : EPOCH 5 - PROGRESS: at 37.39% examples, 311498 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:07,608 : INFO : EPOCH 5 - PROGRESS: at 50.35% examples, 308458 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:08,627 : INFO : EPOCH 5 - PROGRESS: at 63.33% examples, 310245 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:09,650 : INFO : EPOCH 5 - PROGRESS: at 75.99% examples, 309818 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:10,668 : INFO : EPOCH 5 - PROGRESS: at 88.58% examples, 309712 words/s, in_qsize 7, out_qsize 0\n",
            "2021-07-15 03:58:11,459 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-07-15 03:58:11,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-07-15 03:58:11,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-07-15 03:58:11,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-07-15 03:58:11,520 : INFO : EPOCH - 5 : training on 2988089 raw words (2494056 effective words) took 8.0s, 311125 effective words/s\n",
            "2021-07-15 03:58:11,524 : INFO : training on a 14940445 raw words (12471851 effective words) took 39.8s, 313613 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6gRI7xRSwUs"
      },
      "source": [
        "def get_features(words, model, num_features):\n",
        "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
        "\n",
        "    num_words = 0\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "\n",
        "    for w in words:\n",
        "        if w in index2word_set:\n",
        "            num_words += 1\n",
        "            feature_vector = np.add(feature_vector, model[w])\n",
        "\n",
        "    feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dle6aYgPSwUs"
      },
      "source": [
        "def get_dataset(reviews, model, num_features):\n",
        "    dataset = list()\n",
        "\n",
        "    for s in reviews:\n",
        "        dataset.append(get_features(s, model, num_features))\n",
        "\n",
        "    reviewFeatureVecs = np.stack(dataset)\n",
        "    \n",
        "    return reviewFeatureVecs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7BTDNZHSwUt",
        "outputId": "1f9cb588-c70b-438a-9d4c-b9d0db1b32da"
      },
      "source": [
        "test_data_vecs = get_dataset(sentences, model, num_features)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Ut81PuSwUt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X = test_data_vecs\n",
        "y = np.array(sentiments)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_byXdyFSwUu",
        "outputId": "7ef0709d-5edb-4b50-ac5a-b6dbc535eed6"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lgs = LogisticRegression(class_weight='balanced')\n",
        "lgs.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlda58-2SwUu",
        "outputId": "1de246a7-8a28-4a94-ec46-e8f20ffa2037"
      },
      "source": [
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test)) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.864600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUZZrnaRSwUu"
      },
      "source": [
        "TEST_CLEAN_DATA = 'test_clean.csv'\n",
        "\n",
        "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)\n",
        "\n",
        "test_review = list(test_data['review'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7s5H4MJhSwUv",
        "outputId": "a17e3c27-20f5-4d14-8ddf-90b89c95ca24"
      },
      "source": [
        "test_data.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>naturally film main themes mortality nostalgia...</td>\n",
              "      <td>\"12311_10\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>movie disaster within disaster film full great...</td>\n",
              "      <td>\"8348_2\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>movie kids saw tonight child loved one point k...</td>\n",
              "      <td>\"5828_4\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>afraid dark left impression several different ...</td>\n",
              "      <td>\"7186_2\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>accurate depiction small time mob life filmed ...</td>\n",
              "      <td>\"12128_7\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review          id\n",
              "0  naturally film main themes mortality nostalgia...  \"12311_10\"\n",
              "1  movie disaster within disaster film full great...    \"8348_2\"\n",
              "2  movie kids saw tonight child loved one point k...    \"5828_4\"\n",
              "3  afraid dark left impression several different ...    \"7186_2\"\n",
              "4  accurate depiction small time mob life filmed ...   \"12128_7\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_zdLk4dSwUv"
      },
      "source": [
        "test_sentences = list()\n",
        "for review in test_review:\n",
        "    test_sentences.append(review.split())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wx_jSu3SwUv",
        "outputId": "c6eef2a1-21ca-4152-8b41-e91fc88403f3"
      },
      "source": [
        "test_data_vecs = get_dataset(test_sentences, model, num_features)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtpUQWjTSwUv"
      },
      "source": [
        "DATA_OUT_PATH = './data_out/'\n",
        "\n",
        "test_predicted = lgs.predict(test_data_vecs)\n",
        "\n",
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "    os.makedirs(DATA_OUT_PATH)\n",
        "    \n",
        "ids = list(test_data['id'])\n",
        "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
        "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_w2v_answer.csv', index=False, quoting=3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mki89Z7cSwUv",
        "outputId": "edbdd323-cb86-4385-a80c-f89cc3f0337e"
      },
      "source": [
        "model_name = \"300features_40minwords_10context\"\n",
        "model.save(model_name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-15 03:59:16,131 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
            "2021-07-15 03:59:16,133 : INFO : not storing attribute vectors_norm\n",
            "2021-07-15 03:59:16,136 : INFO : not storing attribute cum_table\n",
            "2021-07-15 03:59:16,364 : INFO : saved 300features_40minwords_10context\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}